{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "import numpy as np\n",
    "import random\n",
    "import audiomentations as A\n",
    "import soundfile as sf\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation, Data pre-processing & Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(audio_folder, num_mfcc_coefficients, desired_shape):\n",
    "    preprocessed_data = []\n",
    "    preprocessed_labels = []\n",
    "    \n",
    "    for index, cls in enumerate(os.listdir(audio_folder)):\n",
    "        class_folder = os.path.join(audio_folder, cls)\n",
    "        for file in os.listdir(class_folder)[:15]:\n",
    "            audio_file = os.path.join(class_folder, file)\n",
    "            original_audio, sr = sf.read(audio_file)\n",
    "\n",
    "            # Apply augmentation to create augmented audio\n",
    "            augment1 = A.AddGaussianNoise(p=0.2)\n",
    "            augment2 = A.TimeStretch(p=0.2)\n",
    "            augment3 = A.PitchShift(p=0.2)\n",
    "            augment4 = A.Shift(p=0.2)\n",
    "            augment5 = A.TimeMask(p=0.2)\n",
    "\n",
    "            augmented_audio1 = augment1(samples=original_audio, sample_rate=sr)\n",
    "            augmented_audio2 = augment2(samples=original_audio, sample_rate=sr)\n",
    "            augmented_audio3 = augment3(samples=original_audio, sample_rate=sr)\n",
    "            augmented_audio4 = augment4(samples=original_audio, sample_rate=sr)\n",
    "            augmented_audio5 = augment5(samples=original_audio, sample_rate=sr)\n",
    "\n",
    "            # Perform feature extraction (e.g., MFCCs) on original and augmented audio\n",
    "            for audio in [original_audio, augmented_audio1, augmented_audio2, augmented_audio3, augmented_audio4, augmented_audio5]:\n",
    "                mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=num_mfcc_coefficients)\n",
    "\n",
    "                # Normalize the MFCCs (optional but recommended)\n",
    "                mfccs = (mfccs - np.mean(mfccs)) / np.std(mfccs)\n",
    "\n",
    "                # Reshape or pad the MFCCs to match the desired input shape\n",
    "                num_frames = mfccs.shape[1]\n",
    "                if num_frames < desired_shape[0]:\n",
    "                    mfccs = np.pad(mfccs, ((0, 0), (0, desired_shape[0] - num_frames)), mode='constant')\n",
    "                elif num_frames > desired_shape[0]:\n",
    "                    mfccs = mfccs[:, :desired_shape[0]]\n",
    "\n",
    "                # Append the preprocessed data and label\n",
    "                preprocessed_data.append(mfccs.T)  # Transpose the data\n",
    "                preprocessed_labels.append(index)\n",
    "\n",
    "    # Stack the preprocessed data into a 3D array\n",
    "    X = np.array(preprocessed_data).reshape(-1,13)\n",
    "    y = np.array(preprocessed_labels)\n",
    "\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the data folder path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your audio folder path\n",
    "audio_folder = \"donateacry\"\n",
    "\n",
    "# Function to remove \".DS_Store\" files\n",
    "def remove_ds_store_files(folder_path):\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file == \".DS_Store\":\n",
    "                ds_store_file_path = os.path.join(root, file)\n",
    "                os.remove(ds_store_file_path)\n",
    "\n",
    "# Remove \".DS_Store\" files from the audio folder\n",
    "remove_ds_store_files(audio_folder)\n",
    "\n",
    "# Now, you can proceed with your audio preprocessing as before\n",
    "num_mfcc_coefficients = 13\n",
    "desired_shape = (1, 13)  # Adjust the desired shape as needed\n",
    "X, y = preprocess_audio(audio_folder, num_mfcc_coefficients, desired_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of audio files: (6, 13)\n",
      "Shape of labels: (6,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-8.20595525e+00,  1.51498114e+00,  2.46539512e-01,\n",
       "         2.50964196e-01,  8.23222623e-03,  1.01491315e-02,\n",
       "         1.43629409e-01, -5.06586207e-03,  6.29581766e-02,\n",
       "         6.96103339e-02,  9.25116507e-02,  3.60205983e-01,\n",
       "         3.23634069e-01],\n",
       "       [-8.20595455e+00,  1.51498127e+00,  2.46539488e-01,\n",
       "         2.50964195e-01,  8.23222287e-03,  1.01490775e-02,\n",
       "         1.43629432e-01, -5.06582251e-03,  6.29582033e-02,\n",
       "         6.96102753e-02,  9.25116539e-02,  3.60206008e-01,\n",
       "         3.23634058e-01],\n",
       "       [-5.38009453e+00,  1.14895034e+00,  1.36143550e-01,\n",
       "         2.62174338e-01,  5.64717576e-02,  5.63273132e-02,\n",
       "         1.87074363e-01,  5.21514863e-02,  1.09254755e-01,\n",
       "         1.26343042e-01,  9.56935063e-02,  3.42191845e-01,\n",
       "         2.15401724e-01],\n",
       "       [-8.20595455e+00,  1.51498127e+00,  2.46539488e-01,\n",
       "         2.50964195e-01,  8.23222287e-03,  1.01490775e-02,\n",
       "         1.43629432e-01, -5.06582251e-03,  6.29582033e-02,\n",
       "         6.96102753e-02,  9.25116539e-02,  3.60206008e-01,\n",
       "         3.23634058e-01],\n",
       "       [-8.20595455e+00,  1.51498127e+00,  2.46539488e-01,\n",
       "         2.50964195e-01,  8.23222287e-03,  1.01490775e-02,\n",
       "         1.43629432e-01, -5.06582251e-03,  6.29582033e-02,\n",
       "         6.96102753e-02,  9.25116539e-02,  3.60206008e-01,\n",
       "         3.23634058e-01],\n",
       "       [-5.01827860e+00,  1.00049090e+00,  2.15128466e-01,\n",
       "         2.17868045e-01,  6.75792545e-02,  6.87660873e-02,\n",
       "         1.51411161e-01,  5.93456998e-02,  1.01463139e-01,\n",
       "         1.05581805e-01,  1.19761311e-01,  2.85505682e-01,\n",
       "         2.62861967e-01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of audio files:\",X.shape)\n",
    "print(\"Shape of labels:\",y.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Decision tree: 0.7560975609756098\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "dt.fit(X_train,y_train)\n",
    "dt_pred = dt.predict(X_test)\n",
    "print(\"Accuracy score of Decision tree:\",accuracy_score(y_test,dt_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Random Forest: 0.9512195121951219\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=32)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "print(\"Accuracy score of Random Forest:\",accuracy_score(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Gradient Boosting: 0.9512195121951219\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train,y_train)\n",
    "gb_pred = gb.predict(X_test)\n",
    "print(\"Accuracy score of Gradient Boosting:\",accuracy_score(y_test,gb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of SVC: 0.3902439024390244\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train,y_train)\n",
    "svm_pred = svm.predict(X_test)\n",
    "print(\"Accuracy score of SVC:\",accuracy_score(y_test,svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ap = \"donateacry\\belly_pain\\69BDA5D6-0276-4462-9BF7-951799563728-1436936185-1.1-m-26-bp.wav\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
